{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC CURVE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# calculate no skill roc curve \n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for the model   \n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='RandomForestClassifier')\n",
    "# axis labels\n",
    "plt.xlabel('FALSE POSITIVE RATE')    \n",
    "plt.ylabel('TRUE POSITIVE RATE')    \n",
    "# show the legend                          \n",
    "plt.legend()                                    \n",
    "# show the plot                                 \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, y_pred)\n",
    "ns_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(y_test, y_pred_1,y_pred_2):\n",
    "    # calculate roc curve\n",
    "    fpr_1, tpr_1, thresholds_1 = roc_curve(y_test, y_pred_1)\n",
    "    fpr_2, tpr_2, thresholds_2 = roc_curve(y_test, y_pred_2)\n",
    "\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    # calculate no skill roc curve \n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    # plot the roc curve for the model   \n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr_1, tpr_1, marker='v', label='RandomForestClassifier_accuracy')\n",
    "    plt.plot(fpr_2, tpr_2, marker='.', label='RandomForestClassifier_roc')\n",
    "\n",
    "    # axis labels\n",
    "    plt.xlabel('FALSE POSITIVE RATE')    \n",
    "    plt.ylabel('TRUE POSITIVE RATE')    \n",
    "    # show the legend                          \n",
    "    plt.legend()                                    \n",
    "    # show the plot                                 \n",
    "    plt.show()\n",
    "    return True                      #to get a return by convention\n",
    "\n",
    "def score_roc_auc (y_test, y_pred_1, y_pred_2):\n",
    "    # calculate scores\n",
    "    ns_auc_1 = roc_auc_score(y_test, y_pred_1)\n",
    "    ns_auc_2 = roc_auc_score(y_test, y_pred_2)\n",
    "   \n",
    "    return [ns_auc_1, ns_auc_2]      #to get a list instead of a tuple\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matthews Correlation Coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "def mat_cor (y_test, y_pred_1, y_pred_2):\n",
    "    mat_cor_1 = matthews_corrcoef(y_test, y_pred_1)\n",
    "    mat_cor_2 = matthews_corrcoef(y_test, y_pred_2)\n",
    "    return [mat_cor_1, mat_cor_2]\n",
    "def conf_matrix (y_test, y_pred_1, y_pred_2):\n",
    "    conf_1 = confusion_matrix(y_test, y_pred_1)\n",
    "    conf_2 = confusion_matrix(y_test, y_pred_2)\n",
    "    return conf_1, conf_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def heatmap_conf (conf_1, conf_2): \n",
    "    sns.heatmap(conf_1, center=True)\n",
    "    sns.heatmap(conf_2, center=True)\n",
    "    plt.show()\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "becode",
   "language": "python",
   "name": "becode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
